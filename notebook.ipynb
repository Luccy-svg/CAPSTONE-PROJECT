{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Project**: Semiconductor Wafer Defect Detection using Deep Learning (CNN)"
      ],
      "metadata": {
        "id": "q1LH8jU53duG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1️⃣ Import Libraries"
      ],
      "metadata": {
        "id": "8iIVniCI3nqR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lSx7TaD93aDS"
      },
      "outputs": [],
      "source": [
        "# Basic setup\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.io as sio\n",
        "idx = pd.RangeIndex(start=0, stop=10)\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "\n",
        "We’re using standard libraries for data loading (scipy.io), preprocessing (numpy, pandas), visualization (matplotlib, seaborn), and model building (TensorFlow/Keras)."
      ],
      "metadata": {
        "id": "I8xldsUV33vj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2️⃣ Load Dataset"
      ],
      "metadata": {
        "id": "EL_0NuYT4Yza"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download the dataset**\n",
        "\n",
        "Use the Kaggle API to ensure you get the full, intact file:"
      ],
      "metadata": {
        "id": "xoC0N2_QAfRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!echo '{\"username\":\"YOUR_KAGGLE_USERNAME\",\"key\":\"YOUR_KAGGLE_KEY\"}' > ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d qingyi/wm811k-wafer-map\n",
        "!unzip -o wm811k-wafer-map.zip -d wm811k_dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqAPZb3C-SMr",
        "outputId": "3de4becc-3b0f-4889-b6d5-f17777ec84db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n",
            "Dataset URL: https://www.kaggle.com/datasets/qingyi/wm811k-wafer-map\n",
            "License(s): CC0-1.0\n",
            "Downloading wm811k-wafer-map.zip to /content\n",
            " 98% 146M/149M [00:00<00:00, 1.52GB/s]\n",
            "100% 149M/149M [00:00<00:00, 1.41GB/s]\n",
            "Archive:  wm811k-wafer-map.zip\n",
            "  inflating: wm811k_dataset/LSWMD.pkl  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir('wm811k_dataset')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXu46Uqw-gST",
        "outputId": "dfc16d64-217a-4f49-a238-ba0043000bf6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['LSWMD.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step-by-Step: Safely Loading LSWMD.pkl**\n",
        " 1. Check the File Size First\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GS4DgEioAwgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.path.getsize('wm811k_dataset/LSWMD.pkl') / 1024**2, \"MB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kV3dWnAN_KoS",
        "outputId": "2a24b61e-8382-493a-a47a-d97ffeb29db9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1998.430230140686 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Load the Dataset"
      ],
      "metadata": {
        "id": "NhOu8DO7BDrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, pickle, pandas as pd\n",
        "import pandas.core.indexes as new_indexes\n",
        "sys.modules['pandas.indexes'] = new_indexes  # redirect old pandas path\n",
        "\n",
        "with open('wm811k_dataset/LSWMD.pkl', 'rb') as f:\n",
        "    data = pickle.load(f, encoding='latin1')\n"
      ],
      "metadata": {
        "id": "kg60v0wd_RR6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Inspect the Loaded Data"
      ],
      "metadata": {
        "id": "kw1ZN3OQBOp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(data))\n",
        "print(data.keys())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm-x-nNb_aIf",
        "outputId": "be895ef3-fe5b-4fb9-a423-1329270a7a60"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index(['waferMap', 'dieSize', 'lotName', 'waferIndex', 'trianTestLabel',\n",
            "       'failureType'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wafer_maps = data['waferMap']\n",
        "labels = data['failureType']\n",
        "train_test_split = data['trianTestLabel'] # Corrected key\n",
        "\n",
        "print(f\"Number of wafer maps: {len(wafer_maps)}\")\n",
        "print(f\"Example label: {labels[0][0][0]}\")\n",
        "print(f\"Example wafer map shape: {wafer_maps[0].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ra3ZqK64dl6",
        "outputId": "6a5776be-a1f3-421d-f9d0-e04f6f789368"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of wafer maps: 811457\n",
            "Example label: none\n",
            "Example wafer map shape: (45, 48)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import cv2\n",
        "\n",
        "# Filter out entries with empty failureType lists and flatten labels\n",
        "filtered_data = data[data['failureType'].apply(lambda x: len(x) > 0)]\n",
        "labels = np.array([lbl[0][0] for lbl in filtered_data['failureType']])\n",
        "\n",
        "# Resize wafer maps to uniform shape\n",
        "RESIZE_SHAPE = (48, 48)\n",
        "# Apply the same filtering to wafer maps\n",
        "X = np.array([cv2.resize(img, RESIZE_SHAPE, interpolation=cv2.INTER_NEAREST) for img in filtered_data['waferMap']])\n",
        "\n",
        "# Normalize pixel values\n",
        "X = X / np.max(X)\n",
        "\n",
        "# Encode labels\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(labels)\n",
        "\n",
        "# Show shape summary\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "print(\"Classes:\", encoder.classes_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdBadtCEDWIH",
        "outputId": "6a0ffbef-c642-4560-dfa0-60f217fc0c3c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (172950, 48, 48)\n",
            "y shape: (172950,)\n",
            "Classes: ['Center' 'Donut' 'Edge-Loc' 'Edge-Ring' 'Loc' 'Near-full' 'Random'\n",
            " 'Scratch' 'none']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Replace 'Loc' with 'Edge-Loc' for consistency\n",
        "y_labels = np.array([lbl.replace('Loc', 'Edge-Loc') if lbl == 'Loc' else lbl for lbl in labels])\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(y_labels)\n",
        "print(\"Updated classes:\", encoder.classes_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lzq_BZWD7HN",
        "outputId": "bcebc566-8458-46b4-8de4-3ea2f3151c94"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated classes: ['Center' 'Donut' 'Edge-Loc' 'Edge-Ring' 'Near-full' 'Random' 'Scratch'\n",
            " 'none']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building and training the CNN\n",
        "\n",
        "Build and evaluate two baseline models for wafer defect classification:\n",
        "\n",
        "1. Logistic Regression\n",
        "\n",
        "2. Naive Bayes\n",
        "\n",
        "…and handle class imbalance using:\n",
        "\n",
        "1. Class weights or\n",
        "\n",
        "2. Resampling (SMOTE / undersampling)"
      ],
      "metadata": {
        "id": "fkSUxT7nH359"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Prepare Data for Baselines**\n",
        "\n",
        "Since both Logistic Regression and Naive Bayes require 1D feature vectors, we’ll flatten the wafer images and optionally sample a manageable subset (since 170K+ samples may be heavy)."
      ],
      "metadata": {
        "id": "Yz5fugf0ImKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# --- sample a smaller subset for quick baselines ---\n",
        "X_train_small, y_train_small = resample(X_train_flat, y_train_flat,\n",
        "                                        n_samples=20000, random_state=42, stratify=y_train_flat)\n",
        "X_test_small, y_test_small = resample(X_test_flat, y_test_flat,\n",
        "                                      n_samples=5000, random_state=42, stratify=y_test_flat)\n",
        "\n",
        "print(\"Train subset:\", X_train_small.shape)\n",
        "print(\"Test subset:\", X_test_small.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsUikdutFb5l",
        "outputId": "7afe8af5-c14a-45d9-f1d8-db0230b09e47"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train subset: (20000, 2304)\n",
            "Test subset: (5000, 2304)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Dimensionality Reduction with PCA**\n",
        "\n"
      ],
      "metadata": {
        "id": "_pXVtZUOJTSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce from 2304 → 100 features for speed\n",
        "pca = PCA(n_components=100, random_state=42)\n",
        "X_train_pca = pca.fit_transform(X_train_small)\n",
        "X_test_pca = pca.transform(X_test_small)\n",
        "\n",
        "print(\"After PCA:\", X_train_pca.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHAlvr5GIuPp",
        "outputId": "911771dd-be30-470b-d192-74a51af8f3ef"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After PCA: (20000, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Logistic Regression Baseline**"
      ],
      "metadata": {
        "id": "fn0VDJI_KKk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# compute balanced weights for the subset\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_small), y=y_train_small)\n",
        "cw_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# train Logistic Regression\n",
        "logreg = LogisticRegression(max_iter=100, solver='sag',\n",
        "                            class_weight=cw_dict, n_jobs=-1, verbose=0)\n",
        "logreg.fit(X_train_pca, y_train_small)\n",
        "\n",
        "# predict\n",
        "y_pred_lr = logreg.predict(X_test_pca)\n",
        "\n",
        "print(\"=== Logistic Regression (PCA + subset) ===\")\n",
        "print(\"Accuracy:\", round(accuracy_score(y_test_small, y_pred_lr), 4))\n",
        "print(classification_report(y_test_small, y_pred_lr, target_names=encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCkVxYzjJcqx",
        "outputId": "729a15eb-2987-46f1-fb21-fa8679d72e80"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Logistic Regression (PCA + subset) ===\n",
            "Accuracy: 0.6936\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Center       0.57      0.94      0.71       124\n",
            "       Donut       0.30      0.94      0.45        16\n",
            "    Edge-Loc       0.20      0.48      0.28       254\n",
            "   Edge-Ring       0.90      0.96      0.93       280\n",
            "   Near-full       0.33      1.00      0.50         4\n",
            "      Random       0.26      0.24      0.25        25\n",
            "     Scratch       0.02      0.34      0.03        35\n",
            "        none       0.98      0.69      0.81      4262\n",
            "\n",
            "    accuracy                           0.69      5000\n",
            "   macro avg       0.44      0.70      0.49      5000\n",
            "weighted avg       0.91      0.69      0.77      5000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes Baseline (with Oversampling)**"
      ],
      "metadata": {
        "id": "lClFHWrSRdSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# balance training data for Naive Bayes\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_res, y_res = ros.fit_resample(X_train_pca, y_train_small)\n",
        "\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_res, y_res)\n",
        "y_pred_nb = nb.predict(X_test_pca)\n",
        "\n",
        "print(\"\\n=== Naive Bayes (PCA + oversampled subset) ===\")\n",
        "print(\"Accuracy:\", round(accuracy_score(y_test_small, y_pred_nb), 4))\n",
        "print(classification_report(y_test_small, y_pred_nb, target_names=encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-1xDW7ZKSYR",
        "outputId": "4b2e2ab2-ef99-44ff-bd11-86e30a17ab64"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Naive Bayes (PCA + oversampled subset) ===\n",
            "Accuracy: 0.6626\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Center       0.85      0.63      0.72       124\n",
            "       Donut       0.46      0.81      0.59        16\n",
            "    Edge-Loc       0.27      0.48      0.34       254\n",
            "   Edge-Ring       0.86      0.86      0.86       280\n",
            "   Near-full       0.75      0.75      0.75         4\n",
            "      Random       0.49      0.84      0.62        25\n",
            "     Scratch       0.01      0.49      0.03        35\n",
            "        none       0.97      0.66      0.79      4262\n",
            "\n",
            "    accuracy                           0.66      5000\n",
            "   macro avg       0.58      0.69      0.59      5000\n",
            "weighted avg       0.91      0.66      0.76      5000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quick Comparison Summary**"
      ],
      "metadata": {
        "id": "csD74ZXPTKTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nSummary of Baselines:\")\n",
        "print(f\"Logistic Regression Accuracy: {accuracy_score(y_test_small, y_pred_lr):.3f}\")\n",
        "print(f\"Naive Bayes Accuracy:         {accuracy_score(y_test_small, y_pred_nb):.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF5raw41Rp_v",
        "outputId": "19dc5189-f012-41e5-b513-0d734828934a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary of Baselines:\n",
            "Logistic Regression Accuracy: 0.694\n",
            "Naive Bayes Accuracy:         0.663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.config.list_physical_devices('GPU'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dz1jyou9UgNZ",
        "outputId": "93d1504a-e4a7-4e2c-cc50-1f22923febfb"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Advanced Model: Convolutional Neural Network (CNN)**"
      ],
      "metadata": {
        "id": "VzW2XNM_XYIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "W-MH9W5xXHus"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare Your Data**\n",
        "\n",
        "Ensure:\n",
        "\n",
        "Your X contains wafer maps (48×48)\n",
        "\n",
        "Your y contains encoded defect classes"
      ],
      "metadata": {
        "id": "9uB_z_ZuX19K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Add channel dimension for CNN\n",
        "X = np.expand_dims(X, axis=-1)\n",
        "X = X / 255.0 if X.max() > 1 else X  # normalize if not already scaled\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)\n"
      ],
      "metadata": {
        "id": "LHuF5H8iXwUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0PbT3PLTX9h0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}